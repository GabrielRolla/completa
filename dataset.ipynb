{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144069/4122043005.py:58: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_modelagem = pd.read_sql(query_target, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_demo = pd.read_sql(query_demo, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:74: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
      "/tmp/ipykernel_144069/4122043005.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_top_diag = pd.read_sql(query_top_diag, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:102: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_dx = pd.read_sql(query_dx, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:147: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vaso = pd.read_sql(query_vaso, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:163: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vm = pd.read_sql(query_vm, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:172: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tsr = pd.read_sql(query_tsr, conn)\n",
      "/tmp/ipykernel_144069/4122043005.py:191: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scores = pd.read_sql(query_scores, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# üîå Conectar ao banco de dados\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mimiciv\",\n",
    "    user=\"desafio_mimic\",\n",
    "    password=\"desafio_mimic\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ‚öôÔ∏è Tabelas tempor√°rias: interna√ß√£o e mortalidade\n",
    "sql_script = \"\"\"\n",
    "CREATE TEMP TABLE ultima_uti AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        i.subject_id,\n",
    "        i.hadm_id,\n",
    "        i.stay_id,\n",
    "        i.intime,\n",
    "        i.outtime,\n",
    "        p.dod,\n",
    "        a.admittime,\n",
    "        a.dischtime,\n",
    "        a.hospital_expire_flag,\n",
    "        ROW_NUMBER() OVER (PARTITION BY i.subject_id ORDER BY i.outtime DESC) AS rn\n",
    "    FROM mimiciv_icu.icustays i\n",
    "    JOIN mimiciv_hosp.admissions a ON i.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON i.subject_id = p.subject_id\n",
    ") t\n",
    "WHERE rn = 1;\n",
    "\n",
    "CREATE TEMP TABLE pacientes_mortos AS\n",
    "SELECT\n",
    "  subject_id,\n",
    "  stay_id,\n",
    "  CASE\n",
    "    WHEN dod IS NOT NULL AND dod <= outtime THEN '√ìbito intra-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > outtime AND dod <= dischtime THEN '√ìbito hospitalar p√≥s-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > dischtime AND dod <= dischtime + INTERVAL '1 year' THEN '√ìbito em at√© 1 ano ap√≥s alta hospitalar'\n",
    "    ELSE 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "  END AS categoria\n",
    "FROM ultima_uti;\n",
    "\"\"\"\n",
    "cursor.execute(\"ROLLBACK\")\n",
    "cursor.execute(sql_script)\n",
    "conn.commit()\n",
    "\n",
    "# üì• Target\n",
    "query_target = \"\"\"\n",
    "SELECT subject_id, stay_id,\n",
    "  CASE WHEN categoria = 'Sobrevivente (‚â• 1 ano p√≥s-alta)' THEN 0 ELSE 1 END AS target\n",
    "FROM pacientes_mortos;\n",
    "\"\"\"\n",
    "df_modelagem = pd.read_sql(query_target, conn)\n",
    "\n",
    "# üì• Demogr√°ficos\n",
    "query_demo = \"\"\"\n",
    "SELECT DISTINCT p.subject_id, p.gender, p.anchor_age AS idade\n",
    "FROM mimiciv_hosp.patients p\n",
    "JOIN pacientes_mortos pm ON p.subject_id = pm.subject_id;\n",
    "\"\"\"\n",
    "df_demo = pd.read_sql(query_demo, conn)\n",
    "\n",
    "# üì• Charlson\n",
    "query_charlson = \"\"\"\n",
    "SELECT subject_id, charlson_comorbidity_index AS charlson\n",
    "FROM mimiciv_derived.charlson\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
    "\n",
    "# üîó Merge demogr√°ficos + Charlson\n",
    "df_modelagem = df_modelagem.merge(df_demo, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem = df_modelagem.merge(df_charlson, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem[\"charlson\"] = df_modelagem[\"charlson\"].fillna(0)\n",
    "\n",
    "# üì• Diagn√≥sticos mais frequentes\n",
    "query_top_diag = \"\"\"\n",
    "SELECT d.icd_code, COUNT(*) AS freq\n",
    "FROM mimiciv_hosp.diagnoses_icd d\n",
    "JOIN (SELECT DISTINCT subject_id, hadm_id FROM mimiciv_icu.icustays) icu\n",
    "  ON d.subject_id = icu.subject_id AND d.hadm_id = icu.hadm_id\n",
    "JOIN pacientes_mortos pm ON d.subject_id = pm.subject_id\n",
    "WHERE pm.categoria != 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "GROUP BY d.icd_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df_top_diag = pd.read_sql(query_top_diag, conn)\n",
    "top_icds = df_top_diag[\"icd_code\"].tolist()\n",
    "\n",
    "# üì• Diagn√≥sticos por paciente\n",
    "query_dx = \"\"\"\n",
    "SELECT DISTINCT subject_id, icd_code\n",
    "FROM mimiciv_hosp.diagnoses_icd\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_dx = pd.read_sql(query_dx, conn)\n",
    "\n",
    "# üî¢ Criar flags bin√°rias para diagn√≥sticos\n",
    "df_dx_flags = df_dx[[\"subject_id\"]].drop_duplicates().copy()\n",
    "for icd in top_icds:\n",
    "    col = f\"dx_{icd}\"\n",
    "    df_dx_flags[col] = df_dx[\"icd_code\"].eq(icd).groupby(df_dx[\"subject_id\"]).transform(\"max\")\n",
    "df_dx_flags = df_dx_flags.drop_duplicates(\"subject_id\")\n",
    "df_modelagem = df_modelagem.merge(df_dx_flags, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Ajuste final de colunas dx_ (tira espa√ßos e transforma em int)\n",
    "df_modelagem.columns = df_modelagem.columns.str.strip()\n",
    "dx_cols = [col for col in df_modelagem.columns if col.startswith(\"dx_\")]\n",
    "df_modelagem[dx_cols] = df_modelagem[dx_cols].fillna(0).astype(int)\n",
    "\n",
    "# üì• Vasopressores\n",
    "query_vaso = \"\"\"\n",
    "WITH vaso_flag AS (\n",
    "    SELECT\n",
    "        v.stay_id,\n",
    "        MAX(CASE WHEN v.dopamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dopamine,\n",
    "        MAX(CASE WHEN v.epinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_epinephrine,\n",
    "        MAX(CASE WHEN v.norepinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_norepi,\n",
    "        MAX(CASE WHEN v.phenylephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_pheny,\n",
    "        MAX(CASE WHEN v.dobutamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dobutamine,\n",
    "        MAX(CASE WHEN v.milrinone IS NOT NULL THEN 1 ELSE 0 END) AS vaso_milrinone\n",
    "    FROM mimiciv_derived.vasoactive_agent v\n",
    "    GROUP BY v.stay_id\n",
    "),\n",
    "vasopressin_flag AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS vaso_vasopressin\n",
    "    FROM mimiciv_derived.vasopressin\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(vf.stay_id, vp.stay_id) AS stay_id,\n",
    "    COALESCE(vf.vaso_dopamine, 0) AS vaso_dopamine,\n",
    "    COALESCE(vf.vaso_epinephrine, 0) AS vaso_epinephrine,\n",
    "    COALESCE(vf.vaso_norepi, 0) AS vaso_norepi,\n",
    "    COALESCE(vf.vaso_pheny, 0) AS vaso_pheny,\n",
    "    COALESCE(vf.vaso_dobutamine, 0) AS vaso_dobutamine,\n",
    "    COALESCE(vf.vaso_milrinone, 0) AS vaso_milrinone,\n",
    "    COALESCE(vp.vaso_vasopressin, 0) AS vaso_vasopressin\n",
    "FROM vaso_flag vf\n",
    "FULL OUTER JOIN vasopressin_flag vp ON vf.stay_id = vp.stay_id;\n",
    "\"\"\"\n",
    "df_vaso = pd.read_sql(query_vaso, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vaso, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• Ventila√ß√£o Mec√¢nica\n",
    "query_vm = \"\"\"\n",
    "WITH ventilacao_mec AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS usou_vm\n",
    "    FROM mimiciv_derived.ventilation\n",
    "    WHERE ventilation_status IN ('InvasiveVent', 'NonInvasiveVent', 'SupplementalOxygen', 'HFNC', 'Tracheostomy')\n",
    ")\n",
    "SELECT \n",
    "    u.stay_id,\n",
    "    COALESCE(v.usou_vm, 0) AS usou_vm\n",
    "FROM ultima_uti u\n",
    "LEFT JOIN ventilacao_mec v ON u.stay_id = v.stay_id;\n",
    "\"\"\"\n",
    "df_vm = pd.read_sql(query_vm, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vm, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• TSR\n",
    "query_tsr = \"\"\"\n",
    "SELECT DISTINCT stay_id, 1 AS usou_tsr\n",
    "FROM mimiciv_derived.first_day_rrt\n",
    "WHERE dialysis_present = 1;\n",
    "\"\"\"\n",
    "df_tsr = pd.read_sql(query_tsr, conn)\n",
    "df_modelagem = df_modelagem.merge(df_tsr, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• SAPSII, OASIS, SOFA\n",
    "query_scores = \"\"\"\n",
    "SELECT \n",
    "    p.subject_id,\n",
    "    MAX(s.sapsii) AS sapsii,\n",
    "    MAX(s.sapsii_prob) AS sapsii_prob,\n",
    "    MAX(o.oasis) AS oasis,\n",
    "    MAX(o.oasis_prob) AS oasis_prob,\n",
    "    MAX(f.sofa_24hours) AS sofa_24hours\n",
    "FROM mimiciv_icu.icustays p\n",
    "JOIN mimiciv_derived.sapsii s ON p.stay_id = s.stay_id\n",
    "JOIN mimiciv_derived.oasis o ON p.stay_id = o.stay_id\n",
    "JOIN mimiciv_derived.sofa f ON p.stay_id = f.stay_id\n",
    "JOIN pacientes_mortos pm ON p.stay_id = pm.stay_id\n",
    "GROUP BY p.subject_id;\n",
    "\"\"\"\n",
    "df_scores = pd.read_sql(query_scores, conn)\n",
    "df_modelagem = df_modelagem.merge(df_scores, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Final: preencher NaNs\n",
    "df_modelagem.fillna(0, inplace=True)\n",
    "\n",
    "# üíæ Exportar CSV\n",
    "df_modelagem.to_csv(\"dataset_modelagem_completo.csv\", index=False)\n",
    "print(\"üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167189/3764901025.py:89: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_exames = pd.read_sql(query_exames, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:97: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_modelagem = pd.read_sql(query_target, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:105: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_demo = pd.read_sql(query_demo, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:113: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
      "/tmp/ipykernel_167189/3764901025.py:132: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_top_diag = pd.read_sql(query_top_diag, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:141: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_dx = pd.read_sql(query_dx, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:189: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vaso = pd.read_sql(query_vaso, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:205: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vm = pd.read_sql(query_vm, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:214: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tsr = pd.read_sql(query_tsr, conn)\n",
      "/tmp/ipykernel_167189/3764901025.py:233: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scores = pd.read_sql(query_scores, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# üîå Conectar ao banco de dados\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mimiciv\",\n",
    "    user=\"desafio_mimic\",\n",
    "    password=\"desafio_mimic\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ‚öôÔ∏è Tabelas tempor√°rias: interna√ß√£o e mortalidade\n",
    "sql_script = \"\"\"\n",
    "CREATE TEMP TABLE ultima_uti AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        i.subject_id,\n",
    "        i.hadm_id,\n",
    "        i.stay_id,\n",
    "        i.intime,\n",
    "        i.outtime,\n",
    "        p.dod,\n",
    "        a.admittime,\n",
    "        a.dischtime,\n",
    "        a.hospital_expire_flag,\n",
    "        ROW_NUMBER() OVER (PARTITION BY i.subject_id ORDER BY i.outtime DESC) AS rn\n",
    "    FROM mimiciv_icu.icustays i\n",
    "    JOIN mimiciv_hosp.admissions a ON i.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON i.subject_id = p.subject_id\n",
    ") t\n",
    "WHERE rn = 1;\n",
    "\n",
    "CREATE TEMP TABLE pacientes_mortos AS\n",
    "SELECT\n",
    "  subject_id,\n",
    "  stay_id,\n",
    "  CASE\n",
    "    WHEN dod IS NOT NULL AND dod <= outtime THEN '√ìbito intra-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > outtime AND dod <= dischtime THEN '√ìbito hospitalar p√≥s-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > dischtime AND dod <= dischtime + INTERVAL '1 year' THEN '√ìbito em at√© 1 ano ap√≥s alta hospitalar'\n",
    "    ELSE 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "  END AS categoria\n",
    "FROM ultima_uti;\n",
    "\"\"\"\n",
    "cursor.execute(\"ROLLBACK\")\n",
    "cursor.execute(sql_script)\n",
    "conn.commit()\n",
    "\n",
    "# üì• Exames: Obter a m√©dia, vari√¢ncia e o √∫ltimo exame\n",
    "query_exames = \"\"\"\n",
    "WITH exames_filtrados AS (\n",
    "    SELECT\n",
    "        e.subject_id,\n",
    "        e.valuenum,\n",
    "        e.charttime,\n",
    "        ROW_NUMBER() OVER (PARTITION BY e.subject_id ORDER BY e.charttime DESC) AS rn\n",
    "    FROM mimiciv_icu.chartevents e\n",
    "    JOIN pacientes_mortos pm ON e.stay_id = pm.stay_id\n",
    "    WHERE e.valuenum IS NOT NULL\n",
    "),\n",
    "estatisticas_exames AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        AVG(valuenum) AS media,\n",
    "        VARIANCE(valuenum) AS variancia\n",
    "    FROM exames_filtrados\n",
    "    GROUP BY subject_id\n",
    "),\n",
    "ultimo_exame AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        valuenum AS ultimo_valor\n",
    "    FROM exames_filtrados\n",
    "    WHERE rn = 1\n",
    ")\n",
    "SELECT \n",
    "    e.subject_id,\n",
    "    e.media,\n",
    "    e.variancia,\n",
    "    u.ultimo_valor\n",
    "FROM estatisticas_exames e\n",
    "JOIN ultimo_exame u ON e.subject_id = u.subject_id;\n",
    "\"\"\"\n",
    "\n",
    "# Carregar os resultados da consulta SQL\n",
    "df_exames = pd.read_sql(query_exames, conn)\n",
    "\n",
    "# üì• Target\n",
    "query_target = \"\"\"\n",
    "SELECT subject_id, stay_id,\n",
    "  CASE WHEN categoria = 'Sobrevivente (‚â• 1 ano p√≥s-alta)' THEN 0 ELSE 1 END AS target\n",
    "FROM pacientes_mortos;\n",
    "\"\"\"\n",
    "df_modelagem = pd.read_sql(query_target, conn)\n",
    "\n",
    "# üì• Demogr√°ficos\n",
    "query_demo = \"\"\"\n",
    "SELECT DISTINCT p.subject_id, p.gender, p.anchor_age AS idade\n",
    "FROM mimiciv_hosp.patients p\n",
    "JOIN pacientes_mortos pm ON p.subject_id = pm.subject_id;\n",
    "\"\"\"\n",
    "df_demo = pd.read_sql(query_demo, conn)\n",
    "\n",
    "# üì• Charlson\n",
    "query_charlson = \"\"\"\n",
    "SELECT subject_id, charlson_comorbidity_index AS charlson\n",
    "FROM mimiciv_derived.charlson\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
    "\n",
    "# üîó Merge demogr√°ficos + Charlson\n",
    "df_modelagem = df_modelagem.merge(df_demo, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem = df_modelagem.merge(df_charlson, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem[\"charlson\"] = df_modelagem[\"charlson\"].fillna(0)\n",
    "\n",
    "# üì• Diagn√≥sticos mais frequentes\n",
    "query_top_diag = \"\"\"\n",
    "SELECT d.icd_code, COUNT(*) AS freq\n",
    "FROM mimiciv_hosp.diagnoses_icd d\n",
    "JOIN (SELECT DISTINCT subject_id, hadm_id FROM mimiciv_icu.icustays) icu\n",
    "  ON d.subject_id = icu.subject_id AND d.hadm_id = icu.hadm_id\n",
    "JOIN pacientes_mortos pm ON d.subject_id = pm.subject_id\n",
    "WHERE pm.categoria != 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "GROUP BY d.icd_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df_top_diag = pd.read_sql(query_top_diag, conn)\n",
    "top_icds = df_top_diag[\"icd_code\"].tolist()\n",
    "\n",
    "# üì• Diagn√≥sticos por paciente\n",
    "query_dx = \"\"\"\n",
    "SELECT DISTINCT subject_id, icd_code\n",
    "FROM mimiciv_hosp.diagnoses_icd\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_dx = pd.read_sql(query_dx, conn)\n",
    "\n",
    "# üî¢ Criar flags bin√°rias para diagn√≥sticos\n",
    "df_dx_flags = df_dx[[\"subject_id\"]].drop_duplicates().copy()\n",
    "for icd in top_icds:\n",
    "    col = f\"dx_{icd}\"\n",
    "    df_dx_flags[col] = df_dx[\"icd_code\"].eq(icd).groupby(df_dx[\"subject_id\"]).transform(\"max\")\n",
    "df_dx_flags = df_dx_flags.drop_duplicates(\"subject_id\")\n",
    "df_modelagem = df_modelagem.merge(df_dx_flags, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Ajuste final de colunas dx_ (tira espa√ßos e transforma em int)\n",
    "df_modelagem.columns = df_modelagem.columns.str.strip()\n",
    "dx_cols = [col for col in df_modelagem.columns if col.startswith(\"dx_\")]\n",
    "df_modelagem[dx_cols] = df_modelagem[dx_cols].fillna(0).astype(int)\n",
    "\n",
    "# üîß Merge de exames com o dataset final\n",
    "df_modelagem = df_modelagem.merge(df_exames, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üì• Vasopressores\n",
    "query_vaso = \"\"\"\n",
    "WITH vaso_flag AS (\n",
    "    SELECT\n",
    "        v.stay_id,\n",
    "        MAX(CASE WHEN v.dopamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dopamine,\n",
    "        MAX(CASE WHEN v.epinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_epinephrine,\n",
    "        MAX(CASE WHEN v.norepinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_norepi,\n",
    "        MAX(CASE WHEN v.phenylephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_pheny,\n",
    "        MAX(CASE WHEN v.dobutamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dobutamine,\n",
    "        MAX(CASE WHEN v.milrinone IS NOT NULL THEN 1 ELSE 0 END) AS vaso_milrinone\n",
    "    FROM mimiciv_derived.vasoactive_agent v\n",
    "    GROUP BY v.stay_id\n",
    "),\n",
    "vasopressin_flag AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS vaso_vasopressin\n",
    "    FROM mimiciv_derived.vasopressin\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(vf.stay_id, vp.stay_id) AS stay_id,\n",
    "    COALESCE(vf.vaso_dopamine, 0) AS vaso_dopamine,\n",
    "    COALESCE(vf.vaso_epinephrine, 0) AS vaso_epinephrine,\n",
    "    COALESCE(vf.vaso_norepi, 0) AS vaso_norepi,\n",
    "    COALESCE(vf.vaso_pheny, 0) AS vaso_pheny,\n",
    "    COALESCE(vf.vaso_dobutamine, 0) AS vaso_dobutamine,\n",
    "    COALESCE(vf.vaso_milrinone, 0) AS vaso_milrinone,\n",
    "    COALESCE(vp.vaso_vasopressin, 0) AS vaso_vasopressin\n",
    "FROM vaso_flag vf\n",
    "FULL OUTER JOIN vasopressin_flag vp ON vf.stay_id = vp.stay_id;\n",
    "\"\"\"\n",
    "df_vaso = pd.read_sql(query_vaso, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vaso, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• Ventila√ß√£o Mec√¢nica\n",
    "query_vm = \"\"\"\n",
    "WITH ventilacao_mec AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS usou_vm\n",
    "    FROM mimiciv_derived.ventilation\n",
    "    WHERE ventilation_status IN ('InvasiveVent', 'NonInvasiveVent', 'SupplementalOxygen', 'HFNC', 'Tracheostomy')\n",
    ")\n",
    "SELECT \n",
    "    u.stay_id,\n",
    "    COALESCE(v.usou_vm, 0) AS usou_vm\n",
    "FROM ultima_uti u\n",
    "LEFT JOIN ventilacao_mec v ON u.stay_id = v.stay_id;\n",
    "\"\"\"\n",
    "df_vm = pd.read_sql(query_vm, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vm, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• TSR\n",
    "query_tsr = \"\"\"\n",
    "SELECT DISTINCT stay_id, 1 AS usou_tsr\n",
    "FROM mimiciv_derived.first_day_rrt\n",
    "WHERE dialysis_present = 1;\n",
    "\"\"\"\n",
    "df_tsr = pd.read_sql(query_tsr, conn)\n",
    "df_modelagem = df_modelagem.merge(df_tsr, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• SAPSII, OASIS, SOFA\n",
    "query_scores = \"\"\"\n",
    "SELECT \n",
    "    p.subject_id,\n",
    "    MAX(s.sapsii) AS sapsii,\n",
    "    MAX(s.sapsii_prob) AS sapsii_prob,\n",
    "    MAX(o.oasis) AS oasis,\n",
    "    MAX(o.oasis_prob) AS oasis_prob,\n",
    "    MAX(f.sofa_24hours) AS sofa_24hours\n",
    "FROM mimiciv_icu.icustays p\n",
    "JOIN mimiciv_derived.sapsii s ON p.stay_id = s.stay_id\n",
    "JOIN mimiciv_derived.oasis o ON p.stay_id = o.stay_id\n",
    "JOIN mimiciv_derived.sofa f ON p.stay_id = f.stay_id\n",
    "JOIN pacientes_mortos pm ON p.stay_id = pm.stay_id\n",
    "GROUP BY p.subject_id;\n",
    "\"\"\"\n",
    "df_scores = pd.read_sql(query_scores, conn)\n",
    "df_modelagem = df_modelagem.merge(df_scores, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Final: preencher NaNs\n",
    "df_modelagem.fillna(0, inplace=True)\n",
    "\n",
    "# Remover duplicatas no DataFrame com base no 'subject_id'\n",
    "df_modelagem = df_modelagem.drop_duplicates(subset=['subject_id'])\n",
    "\n",
    "# üíæ Exportar CSV\n",
    "df_modelagem.to_csv(\"dataset_modelagem_completo.csv\", index=False)\n",
    "print(\"üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167189/2908548875.py:89: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_exames = pd.read_sql(query_exames, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:97: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_modelagem = pd.read_sql(query_target, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:105: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_demo = pd.read_sql(query_demo, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:113: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
      "/tmp/ipykernel_167189/2908548875.py:132: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_top_diag = pd.read_sql(query_top_diag, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:141: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_dx = pd.read_sql(query_dx, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:189: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vaso = pd.read_sql(query_vaso, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:205: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vm = pd.read_sql(query_vm, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:214: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tsr = pd.read_sql(query_tsr, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:233: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scores = pd.read_sql(query_scores, conn)\n",
      "/tmp/ipykernel_167189/2908548875.py:255: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_icu_stats = pd.read_sql(query_icu_stats, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# üîå Conectar ao banco de dados\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mimiciv\",\n",
    "    user=\"desafio_mimic\",\n",
    "    password=\"desafio_mimic\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ‚öôÔ∏è Tabelas tempor√°rias: interna√ß√£o e mortalidade\n",
    "sql_script = \"\"\"\n",
    "CREATE TEMP TABLE ultima_uti AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        i.subject_id,\n",
    "        i.hadm_id,\n",
    "        i.stay_id,\n",
    "        i.intime,\n",
    "        i.outtime,\n",
    "        p.dod,\n",
    "        a.admittime,\n",
    "        a.dischtime,\n",
    "        a.hospital_expire_flag,\n",
    "        ROW_NUMBER() OVER (PARTITION BY i.subject_id ORDER BY i.outtime DESC) AS rn\n",
    "    FROM mimiciv_icu.icustays i\n",
    "    JOIN mimiciv_hosp.admissions a ON i.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON i.subject_id = p.subject_id\n",
    ") t\n",
    "WHERE rn = 1;\n",
    "\n",
    "CREATE TEMP TABLE pacientes_mortos AS\n",
    "SELECT\n",
    "  subject_id,\n",
    "  stay_id,\n",
    "  CASE\n",
    "    WHEN dod IS NOT NULL AND dod <= outtime THEN '√ìbito intra-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > outtime AND dod <= dischtime THEN '√ìbito hospitalar p√≥s-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > dischtime AND dod <= dischtime + INTERVAL '1 year' THEN '√ìbito em at√© 1 ano ap√≥s alta hospitalar'\n",
    "    ELSE 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "  END AS categoria\n",
    "FROM ultima_uti;\n",
    "\"\"\"\n",
    "cursor.execute(\"ROLLBACK\")\n",
    "cursor.execute(sql_script)\n",
    "conn.commit()\n",
    "\n",
    "# üì• Exames: Obter a m√©dia, vari√¢ncia e o √∫ltimo exame\n",
    "query_exames = \"\"\"\n",
    "WITH exames_filtrados AS (\n",
    "    SELECT\n",
    "        e.subject_id,\n",
    "        e.valuenum,\n",
    "        e.charttime,\n",
    "        ROW_NUMBER() OVER (PARTITION BY e.subject_id ORDER BY e.charttime DESC) AS rn\n",
    "    FROM mimiciv_icu.chartevents e\n",
    "    JOIN pacientes_mortos pm ON e.stay_id = pm.stay_id\n",
    "    WHERE e.valuenum IS NOT NULL\n",
    "),\n",
    "estatisticas_exames AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        AVG(valuenum) AS media,\n",
    "        VARIANCE(valuenum) AS variancia\n",
    "    FROM exames_filtrados\n",
    "    GROUP BY subject_id\n",
    "),\n",
    "ultimo_exame AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        valuenum AS ultimo_valor\n",
    "    FROM exames_filtrados\n",
    "    WHERE rn = 1\n",
    ")\n",
    "SELECT \n",
    "    e.subject_id,\n",
    "    e.media,\n",
    "    e.variancia,\n",
    "    u.ultimo_valor\n",
    "FROM estatisticas_exames e\n",
    "JOIN ultimo_exame u ON e.subject_id = u.subject_id;\n",
    "\"\"\"\n",
    "\n",
    "# Carregar os resultados da consulta SQL\n",
    "df_exames = pd.read_sql(query_exames, conn)\n",
    "\n",
    "# üì• Target\n",
    "query_target = \"\"\"\n",
    "SELECT subject_id, stay_id,\n",
    "  CASE WHEN categoria = 'Sobrevivente (‚â• 1 ano p√≥s-alta)' THEN 0 ELSE 1 END AS target\n",
    "FROM pacientes_mortos;\n",
    "\"\"\"\n",
    "df_modelagem = pd.read_sql(query_target, conn)\n",
    "\n",
    "# üì• Demogr√°ficos\n",
    "query_demo = \"\"\"\n",
    "SELECT DISTINCT p.subject_id, p.gender, p.anchor_age AS idade\n",
    "FROM mimiciv_hosp.patients p\n",
    "JOIN pacientes_mortos pm ON p.subject_id = pm.subject_id;\n",
    "\"\"\"\n",
    "df_demo = pd.read_sql(query_demo, conn)\n",
    "\n",
    "# üì• Charlson\n",
    "query_charlson = \"\"\"\n",
    "SELECT subject_id, charlson_comorbidity_index AS charlson\n",
    "FROM mimiciv_derived.charlson\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
    "\n",
    "# üîó Merge demogr√°ficos + Charlson\n",
    "df_modelagem = df_modelagem.merge(df_demo, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem = df_modelagem.merge(df_charlson, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem[\"charlson\"] = df_modelagem[\"charlson\"].fillna(0)\n",
    "\n",
    "# üì• Diagn√≥sticos mais frequentes\n",
    "query_top_diag = \"\"\"\n",
    "SELECT d.icd_code, COUNT(*) AS freq\n",
    "FROM mimiciv_hosp.diagnoses_icd d\n",
    "JOIN (SELECT DISTINCT subject_id, hadm_id FROM mimiciv_icu.icustays) icu\n",
    "  ON d.subject_id = icu.subject_id AND d.hadm_id = icu.hadm_id\n",
    "JOIN pacientes_mortos pm ON d.subject_id = pm.subject_id\n",
    "WHERE pm.categoria != 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "GROUP BY d.icd_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df_top_diag = pd.read_sql(query_top_diag, conn)\n",
    "top_icds = df_top_diag[\"icd_code\"].tolist()\n",
    "\n",
    "# üì• Diagn√≥sticos por paciente\n",
    "query_dx = \"\"\"\n",
    "SELECT DISTINCT subject_id, icd_code\n",
    "FROM mimiciv_hosp.diagnoses_icd\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_dx = pd.read_sql(query_dx, conn)\n",
    "\n",
    "# üî¢ Criar flags bin√°rias para diagn√≥sticos\n",
    "df_dx_flags = df_dx[[\"subject_id\"]].drop_duplicates().copy()\n",
    "for icd in top_icds:\n",
    "    col = f\"dx_{icd}\"\n",
    "    df_dx_flags[col] = df_dx[\"icd_code\"].eq(icd).groupby(df_dx[\"subject_id\"]).transform(\"max\")\n",
    "df_dx_flags = df_dx_flags.drop_duplicates(\"subject_id\")\n",
    "df_modelagem = df_modelagem.merge(df_dx_flags, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Ajuste final de colunas dx_ (tira espa√ßos e transforma em int)\n",
    "df_modelagem.columns = df_modelagem.columns.str.strip()\n",
    "dx_cols = [col for col in df_modelagem.columns if col.startswith(\"dx_\")]\n",
    "df_modelagem[dx_cols] = df_modelagem[dx_cols].fillna(0).astype(int)\n",
    "\n",
    "# üîß Merge de exames com o dataset final\n",
    "df_modelagem = df_modelagem.merge(df_exames, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üì• Vasopressores\n",
    "query_vaso = \"\"\"\n",
    "WITH vaso_flag AS (\n",
    "    SELECT\n",
    "        v.stay_id,\n",
    "        MAX(CASE WHEN v.dopamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dopamine,\n",
    "        MAX(CASE WHEN v.epinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_epinephrine,\n",
    "        MAX(CASE WHEN v.norepinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_norepi,\n",
    "        MAX(CASE WHEN v.phenylephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_pheny,\n",
    "        MAX(CASE WHEN v.dobutamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dobutamine,\n",
    "        MAX(CASE WHEN v.milrinone IS NOT NULL THEN 1 ELSE 0 END) AS vaso_milrinone\n",
    "    FROM mimiciv_derived.vasoactive_agent v\n",
    "    GROUP BY v.stay_id\n",
    "),\n",
    "vasopressin_flag AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS vaso_vasopressin\n",
    "    FROM mimiciv_derived.vasopressin\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(vf.stay_id, vp.stay_id) AS stay_id,\n",
    "    COALESCE(vf.vaso_dopamine, 0) AS vaso_dopamine,\n",
    "    COALESCE(vf.vaso_epinephrine, 0) AS vaso_epinephrine,\n",
    "    COALESCE(vf.vaso_norepi, 0) AS vaso_norepi,\n",
    "    COALESCE(vf.vaso_pheny, 0) AS vaso_pheny,\n",
    "    COALESCE(vf.vaso_dobutamine, 0) AS vaso_dobutamine,\n",
    "    COALESCE(vf.vaso_milrinone, 0) AS vaso_milrinone,\n",
    "    COALESCE(vp.vaso_vasopressin, 0) AS vaso_vasopressin\n",
    "FROM vaso_flag vf\n",
    "FULL OUTER JOIN vasopressin_flag vp ON vf.stay_id = vp.stay_id;\n",
    "\"\"\"\n",
    "df_vaso = pd.read_sql(query_vaso, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vaso, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• Ventila√ß√£o Mec√¢nica\n",
    "query_vm = \"\"\"\n",
    "WITH ventilacao_mec AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS usou_vm\n",
    "    FROM mimiciv_derived.ventilation\n",
    "    WHERE ventilation_status IN ('InvasiveVent', 'NonInvasiveVent', 'SupplementalOxygen', 'HFNC', 'Tracheostomy')\n",
    ")\n",
    "SELECT \n",
    "    u.stay_id,\n",
    "    COALESCE(v.usou_vm, 0) AS usou_vm\n",
    "FROM ultima_uti u\n",
    "LEFT JOIN ventilacao_mec v ON u.stay_id = v.stay_id;\n",
    "\"\"\"\n",
    "df_vm = pd.read_sql(query_vm, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vm, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• TSR\n",
    "query_tsr = \"\"\"\n",
    "SELECT DISTINCT stay_id, 1 AS usou_tsr\n",
    "FROM mimiciv_derived.first_day_rrt\n",
    "WHERE dialysis_present = 1;\n",
    "\"\"\"\n",
    "df_tsr = pd.read_sql(query_tsr, conn)\n",
    "df_modelagem = df_modelagem.merge(df_tsr, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• SAPSII, OASIS, SOFA\n",
    "query_scores = \"\"\"\n",
    "SELECT \n",
    "    p.subject_id,\n",
    "    MAX(s.sapsii) AS sapsii,\n",
    "    MAX(s.sapsii_prob) AS sapsii_prob,\n",
    "    MAX(o.oasis) AS oasis,\n",
    "    MAX(o.oasis_prob) AS oasis_prob,\n",
    "    MAX(f.sofa_24hours) AS sofa_24hours\n",
    "FROM mimiciv_icu.icustays p\n",
    "JOIN mimiciv_derived.sapsii s ON p.stay_id = s.stay_id\n",
    "JOIN mimiciv_derived.oasis o ON p.stay_id = o.stay_id\n",
    "JOIN mimiciv_derived.sofa f ON p.stay_id = f.stay_id\n",
    "JOIN pacientes_mortos pm ON p.stay_id = pm.stay_id\n",
    "GROUP BY p.subject_id;\n",
    "\"\"\"\n",
    "df_scores = pd.read_sql(query_scores, conn)\n",
    "df_modelagem = df_modelagem.merge(df_scores, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üì• N√∫mero de admiss√µes na ICU e tempo de perman√™ncia na ICU\n",
    "query_icu_stats = \"\"\"\n",
    "WITH icu_stats AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        COUNT(*) AS num_admissoes_icu,\n",
    "        SUM(EXTRACT(EPOCH FROM (outtime - intime)) / 3600) AS tempo_total_icu_horas\n",
    "    FROM mimiciv_icu.icustays\n",
    "    GROUP BY subject_id\n",
    ")\n",
    "SELECT \n",
    "    pm.subject_id,\n",
    "    COALESCE(icu.num_admissoes_icu, 0) AS num_admissoes_icu,\n",
    "    COALESCE(icu.tempo_total_icu_horas, 0) AS tempo_total_icu_horas\n",
    "FROM pacientes_mortos pm\n",
    "LEFT JOIN icu_stats icu ON pm.subject_id = icu.subject_id;\n",
    "\"\"\"\n",
    "\n",
    "# Carregar os resultados da consulta SQL\n",
    "df_icu_stats = pd.read_sql(query_icu_stats, conn)\n",
    "\n",
    "# üîó Merge com o DataFrame principal\n",
    "df_modelagem = df_modelagem.merge(df_icu_stats, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# Preencher NaNs com 0 (caso algum paciente n√£o tenha registros na ICU)\n",
    "df_modelagem[\"num_admissoes_icu\"] = df_modelagem[\"num_admissoes_icu\"].fillna(0).astype(int)\n",
    "df_modelagem[\"tempo_total_icu_horas\"] = df_modelagem[\"tempo_total_icu_horas\"].fillna(0)\n",
    "\n",
    "# üîß Final: preencher NaNs\n",
    "df_modelagem.fillna(0, inplace=True)\n",
    "\n",
    "# Remover duplicatas no DataFrame com base no 'subject_id'\n",
    "df_modelagem = df_modelagem.drop_duplicates(subset=['subject_id'])\n",
    "\n",
    "# üíæ Exportar CSV\n",
    "df_modelagem.to_csv(\"dataset_modelagem_completo.csv\", index=False)\n",
    "print(\"üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168341/75131249.py:89: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_exames = pd.read_sql(query_exames, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:97: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_modelagem = pd.read_sql(query_target, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:105: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_demo = pd.read_sql(query_demo, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:113: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
      "/tmp/ipykernel_168341/75131249.py:132: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_top_diag = pd.read_sql(query_top_diag, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:141: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_dx = pd.read_sql(query_dx, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:189: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vaso = pd.read_sql(query_vaso, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:205: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_vm = pd.read_sql(query_vm, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:214: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tsr = pd.read_sql(query_tsr, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:233: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scores = pd.read_sql(query_scores, conn)\n",
      "/tmp/ipykernel_168341/75131249.py:274: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_icu_stats = pd.read_sql(query_icu_stats, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# üîå Conectar ao banco de dados\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mimiciv\",\n",
    "    user=\"desafio_mimic\",\n",
    "    password=\"desafio_mimic\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ‚öôÔ∏è Tabelas tempor√°rias: interna√ß√£o e mortalidade\n",
    "sql_script = \"\"\"\n",
    "CREATE TEMP TABLE ultima_uti AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        i.subject_id,\n",
    "        i.hadm_id,\n",
    "        i.stay_id,\n",
    "        i.intime,\n",
    "        i.outtime,\n",
    "        p.dod,\n",
    "        a.admittime,\n",
    "        a.dischtime,\n",
    "        a.hospital_expire_flag,\n",
    "        ROW_NUMBER() OVER (PARTITION BY i.subject_id ORDER BY i.outtime DESC) AS rn\n",
    "    FROM mimiciv_icu.icustays i\n",
    "    JOIN mimiciv_hosp.admissions a ON i.hadm_id = a.hadm_id\n",
    "    JOIN mimiciv_hosp.patients p ON i.subject_id = p.subject_id\n",
    ") t\n",
    "WHERE rn = 1;\n",
    "\n",
    "CREATE TEMP TABLE pacientes_mortos AS\n",
    "SELECT\n",
    "  subject_id,\n",
    "  stay_id,\n",
    "  CASE\n",
    "    WHEN dod IS NOT NULL AND dod <= outtime THEN '√ìbito intra-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > outtime AND dod <= dischtime THEN '√ìbito hospitalar p√≥s-UTI'\n",
    "    WHEN dod IS NOT NULL AND dod > dischtime AND dod <= dischtime + INTERVAL '1 year' THEN '√ìbito em at√© 1 ano ap√≥s alta hospitalar'\n",
    "    ELSE 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "  END AS categoria\n",
    "FROM ultima_uti;\n",
    "\"\"\"\n",
    "cursor.execute(\"ROLLBACK\")\n",
    "cursor.execute(sql_script)\n",
    "conn.commit()\n",
    "\n",
    "# üì• Exames: Obter a m√©dia, vari√¢ncia e o √∫ltimo exame\n",
    "query_exames = \"\"\"\n",
    "WITH exames_filtrados AS (\n",
    "    SELECT\n",
    "        e.subject_id,\n",
    "        e.valuenum,\n",
    "        e.charttime,\n",
    "        ROW_NUMBER() OVER (PARTITION BY e.subject_id ORDER BY e.charttime DESC) AS rn\n",
    "    FROM mimiciv_icu.chartevents e\n",
    "    JOIN pacientes_mortos pm ON e.stay_id = pm.stay_id\n",
    "    WHERE e.valuenum IS NOT NULL\n",
    "),\n",
    "estatisticas_exames AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        AVG(valuenum) AS media,\n",
    "        VARIANCE(valuenum) AS variancia\n",
    "    FROM exames_filtrados\n",
    "    GROUP BY subject_id\n",
    "),\n",
    "ultimo_exame AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        valuenum AS ultimo_valor\n",
    "    FROM exames_filtrados\n",
    "    WHERE rn = 1\n",
    ")\n",
    "SELECT \n",
    "    e.subject_id,\n",
    "    e.media,\n",
    "    e.variancia,\n",
    "    u.ultimo_valor\n",
    "FROM estatisticas_exames e\n",
    "JOIN ultimo_exame u ON e.subject_id = u.subject_id;\n",
    "\"\"\"\n",
    "\n",
    "# Carregar os resultados da consulta SQL\n",
    "df_exames = pd.read_sql(query_exames, conn)\n",
    "\n",
    "# üì• Target\n",
    "query_target = \"\"\"\n",
    "SELECT subject_id, stay_id,\n",
    "  CASE WHEN categoria = 'Sobrevivente (‚â• 1 ano p√≥s-alta)' THEN 0 ELSE 1 END AS target\n",
    "FROM pacientes_mortos;\n",
    "\"\"\"\n",
    "df_modelagem = pd.read_sql(query_target, conn)\n",
    "\n",
    "# üì• Demogr√°ficos\n",
    "query_demo = \"\"\"\n",
    "SELECT DISTINCT p.subject_id, p.gender, p.anchor_age AS idade\n",
    "FROM mimiciv_hosp.patients p\n",
    "JOIN pacientes_mortos pm ON p.subject_id = pm.subject_id;\n",
    "\"\"\"\n",
    "df_demo = pd.read_sql(query_demo, conn)\n",
    "\n",
    "# üì• Charlson\n",
    "query_charlson = \"\"\"\n",
    "SELECT subject_id, charlson_comorbidity_index AS charlson\n",
    "FROM mimiciv_derived.charlson\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_charlson = pd.read_sql(query_charlson, conn).drop_duplicates('subject_id')\n",
    "\n",
    "# üîó Merge demogr√°ficos + Charlson\n",
    "df_modelagem = df_modelagem.merge(df_demo, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem = df_modelagem.merge(df_charlson, on=\"subject_id\", how=\"left\")\n",
    "df_modelagem[\"charlson\"] = df_modelagem[\"charlson\"].fillna(0)\n",
    "\n",
    "# üì• Diagn√≥sticos mais frequentes\n",
    "query_top_diag = \"\"\"\n",
    "SELECT d.icd_code, COUNT(*) AS freq\n",
    "FROM mimiciv_hosp.diagnoses_icd d\n",
    "JOIN (SELECT DISTINCT subject_id, hadm_id FROM mimiciv_icu.icustays) icu\n",
    "  ON d.subject_id = icu.subject_id AND d.hadm_id = icu.hadm_id\n",
    "JOIN pacientes_mortos pm ON d.subject_id = pm.subject_id\n",
    "WHERE pm.categoria != 'Sobrevivente (‚â• 1 ano p√≥s-alta)'\n",
    "GROUP BY d.icd_code\n",
    "ORDER BY freq DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "df_top_diag = pd.read_sql(query_top_diag, conn)\n",
    "top_icds = df_top_diag[\"icd_code\"].tolist()\n",
    "\n",
    "# üì• Diagn√≥sticos por paciente\n",
    "query_dx = \"\"\"\n",
    "SELECT DISTINCT subject_id, icd_code\n",
    "FROM mimiciv_hosp.diagnoses_icd\n",
    "WHERE subject_id IN (SELECT subject_id FROM pacientes_mortos);\n",
    "\"\"\"\n",
    "df_dx = pd.read_sql(query_dx, conn)\n",
    "\n",
    "# üî¢ Criar flags bin√°rias para diagn√≥sticos\n",
    "df_dx_flags = df_dx[[\"subject_id\"]].drop_duplicates().copy()\n",
    "for icd in top_icds:\n",
    "    col = f\"dx_{icd}\"\n",
    "    df_dx_flags[col] = df_dx[\"icd_code\"].eq(icd).groupby(df_dx[\"subject_id\"]).transform(\"max\")\n",
    "df_dx_flags = df_dx_flags.drop_duplicates(\"subject_id\")\n",
    "df_modelagem = df_modelagem.merge(df_dx_flags, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üîß Ajuste final de colunas dx_ (tira espa√ßos e transforma em int)\n",
    "df_modelagem.columns = df_modelagem.columns.str.strip()\n",
    "dx_cols = [col for col in df_modelagem.columns if col.startswith(\"dx_\")]\n",
    "df_modelagem[dx_cols] = df_modelagem[dx_cols].fillna(0).astype(int)\n",
    "\n",
    "# üîß Merge de exames com o dataset final\n",
    "df_modelagem = df_modelagem.merge(df_exames, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üì• Vasopressores\n",
    "query_vaso = \"\"\"\n",
    "WITH vaso_flag AS (\n",
    "    SELECT\n",
    "        v.stay_id,\n",
    "        MAX(CASE WHEN v.dopamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dopamine,\n",
    "        MAX(CASE WHEN v.epinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_epinephrine,\n",
    "        MAX(CASE WHEN v.norepinephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_norepi,\n",
    "        MAX(CASE WHEN v.phenylephrine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_pheny,\n",
    "        MAX(CASE WHEN v.dobutamine IS NOT NULL THEN 1 ELSE 0 END) AS vaso_dobutamine,\n",
    "        MAX(CASE WHEN v.milrinone IS NOT NULL THEN 1 ELSE 0 END) AS vaso_milrinone\n",
    "    FROM mimiciv_derived.vasoactive_agent v\n",
    "    GROUP BY v.stay_id\n",
    "),\n",
    "vasopressin_flag AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS vaso_vasopressin\n",
    "    FROM mimiciv_derived.vasopressin\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(vf.stay_id, vp.stay_id) AS stay_id,\n",
    "    COALESCE(vf.vaso_dopamine, 0) AS vaso_dopamine,\n",
    "    COALESCE(vf.vaso_epinephrine, 0) AS vaso_epinephrine,\n",
    "    COALESCE(vf.vaso_norepi, 0) AS vaso_norepi,\n",
    "    COALESCE(vf.vaso_pheny, 0) AS vaso_pheny,\n",
    "    COALESCE(vf.vaso_dobutamine, 0) AS vaso_dobutamine,\n",
    "    COALESCE(vf.vaso_milrinone, 0) AS vaso_milrinone,\n",
    "    COALESCE(vp.vaso_vasopressin, 0) AS vaso_vasopressin\n",
    "FROM vaso_flag vf\n",
    "FULL OUTER JOIN vasopressin_flag vp ON vf.stay_id = vp.stay_id;\n",
    "\"\"\"\n",
    "df_vaso = pd.read_sql(query_vaso, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vaso, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• Ventila√ß√£o Mec√¢nica\n",
    "query_vm = \"\"\"\n",
    "WITH ventilacao_mec AS (\n",
    "    SELECT DISTINCT stay_id, 1 AS usou_vm\n",
    "    FROM mimiciv_derived.ventilation\n",
    "    WHERE ventilation_status IN ('InvasiveVent', 'NonInvasiveVent', 'SupplementalOxygen', 'HFNC', 'Tracheostomy')\n",
    ")\n",
    "SELECT \n",
    "    u.stay_id,\n",
    "    COALESCE(v.usou_vm, 0) AS usou_vm\n",
    "FROM ultima_uti u\n",
    "LEFT JOIN ventilacao_mec v ON u.stay_id = v.stay_id;\n",
    "\"\"\"\n",
    "df_vm = pd.read_sql(query_vm, conn)\n",
    "df_modelagem = df_modelagem.merge(df_vm, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• TSR\n",
    "query_tsr = \"\"\"\n",
    "SELECT DISTINCT stay_id, 1 AS usou_tsr\n",
    "FROM mimiciv_derived.first_day_rrt\n",
    "WHERE dialysis_present = 1;\n",
    "\"\"\"\n",
    "df_tsr = pd.read_sql(query_tsr, conn)\n",
    "df_modelagem = df_modelagem.merge(df_tsr, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "# üì• SAPSII, OASIS, SOFA\n",
    "query_scores = \"\"\"\n",
    "SELECT \n",
    "    p.subject_id,\n",
    "    MAX(s.sapsii) AS sapsii,\n",
    "    MAX(s.sapsii_prob) AS sapsii_prob,\n",
    "    MAX(o.oasis) AS oasis,\n",
    "    MAX(o.oasis_prob) AS oasis_prob,\n",
    "    MAX(f.sofa_24hours) AS sofa_24hours\n",
    "FROM mimiciv_icu.icustays p\n",
    "JOIN mimiciv_derived.sapsii s ON p.stay_id = s.stay_id\n",
    "JOIN mimiciv_derived.oasis o ON p.stay_id = o.stay_id\n",
    "JOIN mimiciv_derived.sofa f ON p.stay_id = f.stay_id\n",
    "JOIN pacientes_mortos pm ON p.stay_id = pm.stay_id\n",
    "GROUP BY p.subject_id;\n",
    "\"\"\"\n",
    "df_scores = pd.read_sql(query_scores, conn)\n",
    "df_modelagem = df_modelagem.merge(df_scores, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# üì• N√∫mero de admiss√µes na ICU, tempo de perman√™ncia na ICU, n√∫mero de diagn√≥sticos e n√∫mero de procedimentos\n",
    "# üì• N√∫mero de diagn√≥sticos e procedimentos\n",
    "query_icu_stats = \"\"\"\n",
    "WITH icu_stats AS (\n",
    "    SELECT \n",
    "        subject_id,\n",
    "        COUNT(*) AS num_admissoes_icu,\n",
    "        SUM(EXTRACT(EPOCH FROM (outtime - intime)) / 3600) AS tempo_total_icu_horas\n",
    "    FROM mimiciv_icu.icustays\n",
    "    GROUP BY subject_id\n",
    "),\n",
    "num_diag AS (\n",
    "    SELECT \n",
    "        subject_id, \n",
    "        COUNT(DISTINCT icd_code) AS num_diag\n",
    "    FROM mimiciv_hosp.diagnoses_icd\n",
    "    GROUP BY subject_id\n",
    "),\n",
    "num_proc AS (\n",
    "    SELECT \n",
    "        subject_id, \n",
    "        COUNT(DISTINCT itemid) AS num_proc  -- Alterado para 'itemid' de 'procedureevents'\n",
    "    FROM mimiciv_icu.procedureevents\n",
    "    GROUP BY subject_id\n",
    ")\n",
    "SELECT \n",
    "    pm.subject_id,\n",
    "    COALESCE(icu.num_admissoes_icu, 0) AS num_admissoes_icu,\n",
    "    COALESCE(icu.tempo_total_icu_horas, 0) AS tempo_total_icu_horas,\n",
    "    COALESCE(nd.num_diag, 0) AS num_diag,\n",
    "    COALESCE(np.num_proc, 0) AS num_proc\n",
    "FROM pacientes_mortos pm\n",
    "LEFT JOIN icu_stats icu ON pm.subject_id = icu.subject_id\n",
    "LEFT JOIN num_diag nd ON pm.subject_id = nd.subject_id\n",
    "LEFT JOIN num_proc np ON pm.subject_id = np.subject_id;\n",
    "\"\"\"\n",
    "\n",
    "# Carregar os resultados da consulta SQL\n",
    "df_icu_stats = pd.read_sql(query_icu_stats, conn)\n",
    "\n",
    "# üîó Merge com o DataFrame principal\n",
    "df_modelagem = df_modelagem.merge(df_icu_stats, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# Preencher NaNs com 0 (caso algum paciente n√£o tenha registros na ICU)\n",
    "df_modelagem[\"num_admissoes_icu\"] = df_modelagem[\"num_admissoes_icu\"].fillna(0).astype(int)\n",
    "df_modelagem[\"tempo_total_icu_horas\"] = df_modelagem[\"tempo_total_icu_horas\"].fillna(0)\n",
    "df_modelagem[\"num_diag\"] = df_modelagem[\"num_diag\"].fillna(0).astype(int)\n",
    "df_modelagem[\"num_proc\"] = df_modelagem[\"num_proc\"].fillna(0).astype(int)\n",
    "\n",
    "# üîß Final: preencher NaNs\n",
    "df_modelagem.fillna(0, inplace=True)\n",
    "\n",
    "# Remover duplicatas no DataFrame com base no 'subject_id'\n",
    "df_modelagem = df_modelagem.drop_duplicates(subset=['subject_id'])\n",
    "\n",
    "# üíæ Exportar CSV\n",
    "df_modelagem.to_csv(\"dataset_modelagem_completo.csv\", index=False)\n",
    "print(\"üìÅ Dataset final salvo como: dataset_modelagem_completo.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
